{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_group_7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CreatorClement/b575f20/blob/master/project_group_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfq9kMx4EwR7"
      },
      "source": [
        "Group Homework - Project2 - Drug annotation of 23andme report\n",
        "\n",
        "Group 7 - Tasmine Clement, Charles Zhang, Shengchao Zhao, Julia Rosander\n",
        "\n",
        "Due Date: Dec 1, 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxmlukqFWVRT"
      },
      "source": [
        "<b>Tasmine Clement Answers</b>\n",
        "\n",
        "*What was your biggest challenge in this project? (regarding writing code and not only)*\n",
        "\n",
        "In the beginning it took time to navigate the websites to make sure I had the correct files and all of the docs for the project. The biggest challenge was realizing that even if my code 'works' there may be unintended consequences of trying to fix an error with my corrections (like deleting more lines than necessary in this case).\n",
        "\n",
        "*What did you learn while working on this project? (regarding writing code and not only)*\n",
        "\n",
        "I learned that when working with unknown data, it is very valuable to take some time to explore the data to become familiar with how things are organized because small details can cause errors in code. \n",
        "\n",
        "*If you had more time on the project what other question(s) would you like to answer? (at least one question is required)*\n",
        "\n",
        "What disorders/diseases are most common for genetic variants with drug effects? I also wonder at what levels the author determined associations to be significant. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1EN5i3CWVdK"
      },
      "source": [
        "<b>Julia Rosander Answers </b>\n",
        "\n",
        "*What was your biggest challenge in this project? (regarding writing code and not only)*\n",
        "\n",
        "The biggest challenge was ensuring that the code worked correctly and was also the most efficient way to accomplish the analysis of drug associations.\n",
        "\n",
        "*What did you learn while working on this project? (regarding writing code and not only)*\n",
        "Utilizing dataframes correctly can be tricky prior to doing an exploratory analysis of the data.  It is important to ensure that you understand your methods before applying them to new datasets.\n",
        "\n",
        "*If you had more time on the project what other question(s) would you like to answer? (at least one question is required)*\n",
        "Are there other confounding variables that could affect the interpretation of drug associations that is not inlcuded within this dataset?  This could explored through researching drug associations and running more analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v_af-GAWVkw"
      },
      "source": [
        "<b>Charles Zhang Answers</b>\n",
        "\n",
        "*What was your biggest challenge in this project? (regarding writing code and not only)*\n",
        "\n",
        "\n",
        "Trying to get all the data accurately incorporated into a pandas dataframe when one line contains an error. It was already challenging when I knew that there was an error and had an idea of where it was, but I can see it being very difficult if it's an unknown dataset.\n",
        "\n",
        "*What did you learn while working on this project? (regarding writing code and not only)*\n",
        "\n",
        "Pandas dataframes are super useful and I would use it over other forms of data management like Excel or JMP when proficient.\n",
        "\n",
        "*If you had more time on the project what other question(s) would you like to answer? (at least one question is required)*\n",
        "\n",
        "In what ethnicities are the variants most commonly found in? How closely are the significant drug associations tied to ethnicity?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coIdkTFOWGju"
      },
      "source": [
        "<b>Shengchao Zhao Answers</b>\n",
        "\n",
        "*What was your biggest challenge in this project? (regarding writing code and not only)*\n",
        "\n",
        "The biggest challenge was to catch up Zhang's progress as he was so fast in this assignment. The code part isn't hard at all for it's somehow done once in the homework.\n",
        "\n",
        "*What did you learn while working on this project? (regarding writing code and not only)*\n",
        "\n",
        "The errors that are detected by the editor, no matter how much there is, are the best errors; the errors that aren't detected by the editor, and the code doesn't work, are the fine errors; the errors that aren't detected by the editor, and the code works, are the worst errors.\n",
        "\n",
        "*If you had more time on the project what other question(s) would you like to answer? (at least one question is required)*\n",
        "\n",
        "If we can use deep learning to look for paterns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vko-kiZp-nK2"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYRqxX5gE9Fd"
      },
      "source": [
        "First, to connect the variants to the information available in the PharmGKB  data we needed the var_drug_ann.tsv available in the annotations.zip archive under 'Variant and Clinical Annotations Data': \n",
        "\n",
        "https://www.pharmgkb.org/downloads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS3_UtL1D-66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "38a5a72a-9969-47f2-f6ea-2e80143b496a"
      },
      "source": [
        "var_drug_ann = pd.read_csv(\"var_drug_ann.tsv\", sep='\\t' )\n",
        "\n",
        "var_drug_ann.columns = ['Annotation ID','Variant','GENE_SYMBOL','DRUG_NAME','PMID','PHENOTYPE_CATEGORY','SIGNIFICANCE','NOTES','SENTENCE','StudyParameters','ALLELE_PharmGKB','Chromosome']\n",
        "\n",
        "#loads pharmgkb data into a pandas dataframe and renames the columns to that of the instructions\n",
        "#The error on line 8156 was corrected by balancing the quotation marks beginning and ending at \"The 15-year cumulative....allele (39% vs 19%)\" for the Notes. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-bc9ae3406481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvar_drug_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"var_drug_ann.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvar_drug_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Annotation ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Variant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'GENE_SYMBOL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DRUG_NAME'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PMID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PHENOTYPE_CATEGORY'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SIGNIFICANCE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NOTES'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SENTENCE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'StudyParameters'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ALLELE_PharmGKB'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Chromosome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#loads pharmgkb data into a pandas dataframe and renames the columns to that of the instructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'var_drug_ann.tsv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzXLrqVaIScQ"
      },
      "source": [
        "Retreive the 23andme 23andme_v5_hg19_ref.txt.gz raw data file regarding variants from the following github account: https://github.com/arrogantrobot/23andme2vcf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT0PF4B6FxIt"
      },
      "source": [
        "database = pd.read_csv(\"23andme_v5_hg19_ref.txt\", sep='\\t', names=[\"CHR\", \"POS\", \"dbSNP_ID\", \"ALLELE_23andme\"])\n",
        "\n",
        "#loads 23andme data into a pandas dataframe from the tab separated file and gives them column headers (not found in file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9MsVhmcGb-s"
      },
      "source": [
        "joined = database.merge(var_drug_ann, left_on='dbSNP_ID', right_on='Variant')\n",
        "\n",
        "#merges the 23andme and pharmgkb data using the column dbSNP_ID in the former and Variant in the latter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bggknDkNOKL"
      },
      "source": [
        "joined_filtered = joined.loc[(joined['SIGNIFICANCE'].str.lower() == 'yes') & (joined['PHENOTYPE_CATEGORY'].str.lower() == 'efficacy')].filter(items=['dbSNP_ID', 'GENE_SYMBOL', 'DRUG_NAME', 'NOTES', 'SENTENCE', 'ALLELE_PharmGKB', 'ALLELE_23andme'])\n",
        "\n",
        "#simultaneously filters rows based on if significance is yes (lowered, in case there is yes, Yes, YES, etc) and if phenotype_category is 'efficacy'. Also only includes the columns we were asked to keep."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju6FxcNhOiAH"
      },
      "source": [
        "joined_filtered.to_csv(\"23andme_PharmGKB_map.tsv\", sep=\"\\t\",index=False)\n",
        "\n",
        "#writes to file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdouujzNw2mr"
      },
      "source": [
        "drug_data = pd.DataFrame()\n",
        "for index,row in joined_filtered.itterows():\n",
        "  drug_data.append(row['GENE_SYMBOL'], row['DRUG_NAME']]])\n",
        "\n",
        "#parses two columns from previously filtered dataset and appends to an object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh5qOBSo9rhy"
      },
      "source": [
        "list_dbSNPs = []\n",
        "for index,row in joined_filtered.itterows():\n",
        "  list_dbSNPs.append(row['dbSNP_ID'])\n",
        "\n",
        "drug_data = drug_data.append(list_dbSNPs)\n",
        "#Creates a list of dbSNP IDs and appends to the previously created dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSFrmhVw2sZa"
      },
      "source": [
        "drug_data.to_csv(\"drug_data_23andme_PharmGKB_map.tsv\", sep=\";\",index=False)\n",
        "#creates tab separated file of the previous three columns in the dataset \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}